# TwoGram模型
## Overview
本项目实现了一个2-Gram语言模型，并且通过对这个语言模型进行Viterbi解码，得到了一个简易输入法的展示demo
## 测试环境
本项目在Ubuntu 18.04 + 64位机上测试通过，Python版本为3.7.0
## 实现原理
在这里我就不过多介绍了，大家可以参看我的CSDN中的博文详解。(https://blog.csdn.net/m0_38055352/article/details/84194281)
## 训练数据
我采用的训练数据是百度贴吧中的文本数据，大概1600W条。
## 使用方法
- 进入TwoGram/demo/目录
- 在命令行中输入: python run.py -h，用于查看使用说明
- 根据使用说明对程序进行使用，这里简单说明一下命令行参数
  - -i参数：后面跟一句话的拼音，每两个拼音之间用空格隔开
  - --infile --outfile参数：需要同时使用，前者指定待转化文件目录，后者指定结果存放目录。待转化文件格式为一行放一句话的拼音，同样用空格隔开；不同的话，放在不同的行中。

**需要注意的是，由于训练2-Gram模型需要数据库的支持，我使用的是MongoDB数据库存储百度贴吧文本，所以，如果你没有爬取数据的话，是没办法训练模型的，但是可以使用。
如果有想进行训练的朋友，可以自行爬取数据，或者利用我的另一个项目(https://github.com/AndroidStudio2017/BaiduSpider)
，当然这里也提供的训练所需要的py脚本**
